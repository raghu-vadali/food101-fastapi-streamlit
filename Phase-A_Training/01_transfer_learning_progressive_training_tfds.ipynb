{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9543bdc",
   "metadata": {},
   "source": [
    "# Part-4: Transfer Learning with Progressive data and TFDS (tensorflow data sets)\n",
    "\n",
    "# Also called as progressive training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a164053",
   "metadata": {},
   "source": [
    "### STEP 1: Tensorflow settings for XLA, warning, memory allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c2f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"  # must run before `import tensorflow`\n",
    "\n",
    "# (Optional) also reduce logs:\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e677de9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JIT enabled?  autoclustering\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.optimizer.set_jit(\"autoclustering\")\n",
    "print(\"JIT enabled? \", getattr(tf.config.optimizer, \"get_jit\", lambda: \"n/a\")())\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e6864",
   "metadata": {},
   "source": [
    "### STEP 2:  Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbae201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghu/tf-env/lib/python3.12/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import helper_functions_updated as hf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91853347",
   "metadata": {},
   "source": [
    "### STEP 3:  Import dataset and check files\n",
    "\n",
    "            â—‹ its easy to split data\n",
    "            â—‹ 2-5x Faster Training âš¡\n",
    "            â—‹ Optimal for TensorFlow's data pipeline\n",
    "            â—‹ Better shuffling & prefetching - Excellent\n",
    "            â—‹ Single-file simplicity\n",
    "            â—‹ Built-in compression\n",
    "            â—‹ Memory usage - Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640699bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeaturesDict({\n",
      "    'image': Image(shape=(None, None, 3), dtype=uint8),\n",
      "    'label': ClassLabel(shape=(), dtype=int64, num_classes=101),\n",
      "})\n",
      "{'train': <SplitInfo num_examples=75750, num_shards=32>, 'validation': <SplitInfo num_examples=25250, num_shards=16>}\n",
      "('image', 'label')\n",
      "This dataset consists of 101 food categories, with 101'000 images. For each class, 250 manually reviewed test images are provided as well as 750 training images. On purpose, the training images were not cleaned, and thus still contain some amount of noise. This comes mostly in the form of intense colors and sometimes wrong labels. All images were rescaled to have a maximum side length of 512 pixels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767897900.279511   30678 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5518 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:64:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "                                        \"food101\",\n",
    "                                        split=[\"train\", \"validation\"],\n",
    "                                        shuffle_files=True,\n",
    "                                        as_supervised=True,\n",
    "                                        with_info=True,\n",
    "                                    )\n",
    "\n",
    "print(ds_info.features)\n",
    "print(ds_info.splits)\n",
    "print(ds_info.supervised_keys)\n",
    "print(ds_info.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500602ac",
   "metadata": {},
   "source": [
    "### STEP 4:  Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403bbe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "     \n",
    "# Progressive training splits\n",
    "ds_10p = tfds.load(\n",
    "                        \"food101\",\n",
    "                        split=\"train[:10%]\",\n",
    "                        as_supervised=True,\n",
    "                    )\n",
    "\n",
    "ds_50p = tfds.load(\n",
    "                        \"food101\",\n",
    "                        split=\"train[:50%]\",\n",
    "                        as_supervised=True,\n",
    "                    )\n",
    "\n",
    "ds_100p = tfds.load(\n",
    "                        \"food101\",\n",
    "                        split=\"train\",\n",
    "                        as_supervised=True,\n",
    "                    )\n",
    "\n",
    "# Fixed validation set\n",
    "ds_validation = tfds.load(\n",
    "                        \"food101\",\n",
    "                        split=\"validation\",\n",
    "                        as_supervised=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77767ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 10%: 7575\n",
      "Train 50%: 37875\n",
      "Train 100%: 75750\n",
      "Validation: 25250\n"
     ]
    }
   ],
   "source": [
    "def count_examples(ds):\n",
    "    return sum(1 for _ in ds)\n",
    "\n",
    "print(\"Train 10%:\", count_examples(ds_10p))\n",
    "print(\"Train 50%:\", count_examples(ds_50p))\n",
    "print(\"Train 100%:\", count_examples(ds_100p))\n",
    "print(\"Validation:\", count_examples(ds_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5600a7d",
   "metadata": {},
   "source": [
    "### STEP 5:  Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81062891",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 384\n",
    "BUFFER_SIZE = 1000   # good default for Food101\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8005a538",
   "metadata": {},
   "source": [
    "### STEP 6:  Image processing + Augmentation, shuffle and prefetch for training dataset, which should be outside model\n",
    "\n",
    "      RAW IMAGE\n",
    "         â†“\n",
    "      PREPROCESSING  (deterministic, always on)\n",
    "         â†“\n",
    "      AUGMENTATION   (random, TRAIN ONLY)\n",
    "         â†“\n",
    "      MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a6cbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method defined here is new and moved to tf.keras.layers from tf.keras.layers.experimental.preprocessing\n",
    "# Data Augmentation for incresing the diversity of the training data\n",
    "# Consider XLA (Accelerated Linear Algebra) for speeding up the training which do not support some layers\n",
    "data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "                                         tf.keras.layers.RandomRotation(0.2),\n",
    "                                         tf.keras.layers.RandomZoom(height_factor=0.2, width_factor=0.2)],                                      \n",
    "                                         # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetV2B0\n",
    "                                        name =\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73f92aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "\n",
    "# Preprocessing image\n",
    "def preprocess_fn(image, label):\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = preprocess_input(image)    \n",
    "    return image, label\n",
    "\n",
    "\n",
    "def build_training_dataset(dataset, BUFFER_SIZE, BATCH_SIZE):    \n",
    "    # shuffle images before batching up\n",
    "    dataset_processed = (\n",
    "                            dataset\n",
    "                            .shuffle(BUFFER_SIZE)\n",
    "                            .map(preprocess_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                            .map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "                            .batch(BATCH_SIZE)\n",
    "                            .prefetch(1)\n",
    "                        )\n",
    "    return dataset_processed\n",
    "\n",
    "def build_eval_dataset(dataset, BATCH_SIZE):\n",
    "    return (\n",
    "        dataset\n",
    "        .map(preprocess_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd609f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1767897915.214812   31212 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_train_10: shape = (32, 384, 384, 3), type = <dtype: 'float32'>\n",
      "ds_train_50: shape = (32, 384, 384, 3), type = <dtype: 'float32'>\n",
      "ds_train_100: shape = (32, 384, 384, 3), type = <dtype: 'float32'>\n",
      "ds_val: shape = (32, 384, 384, 3), type = <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "ds_train_10 = build_training_dataset(ds_10p, BUFFER_SIZE, BATCH_SIZE)\n",
    "ds_train_50 = build_training_dataset(ds_50p, BUFFER_SIZE, BATCH_SIZE)\n",
    "ds_train_100 = build_training_dataset(ds_100p, BUFFER_SIZE, BATCH_SIZE)\n",
    "ds_val = build_eval_dataset(ds_validation, BATCH_SIZE)\n",
    "\n",
    "dataset = [ds_train_10, ds_train_50, ds_train_100, ds_val]\n",
    "dataset_names = [\"ds_train_10\", \"ds_train_50\", \"ds_train_100\", \"ds_val\"]\n",
    "for set, name in zip(dataset, dataset_names):\n",
    "    for x, y in set.take(1):\n",
    "        print(f\"{name}: shape = {x.shape}, type = {x.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab0b81",
   "metadata": {},
   "source": [
    "### STEP 7: import Model efficientnetV2S, compile and fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110929b",
   "metadata": {},
   "source": [
    "### Phase 0 setup once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47461d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the checkpoints for model\n",
    "ckpt_model_10p = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoints/ckpt_model_10p.ckpt\",\n",
    "                                               save_weights_only=True,\n",
    "                                               save_best_only=True,\n",
    "                                               monitor=\"val_accuracy\",\n",
    "                                               save_freq=\"epoch\",\n",
    "                                               verbose=1)                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b8cbd9",
   "metadata": {},
   "source": [
    "Use the official preprocessing for EfficientNetV2 after augmentation.\n",
    "- from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "\n",
    "Specify pretrained weights.\n",
    "- base_model = tf.keras.applications.EfficientNetV2S(include_top=False, weights=\"imagenet\")\n",
    "\n",
    "Keep BN stable with training=False (what you did).\n",
    "- a1 = base_model(ax, training=False)\n",
    "\n",
    "(Optional) enable mixed precision on your 4070 for speed.\n",
    "- tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9d64d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    }
   ],
   "source": [
    "# (Optional) speedup on RTX 4070\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "316a55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_food101_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=101, dropout_rate=0.5):\n",
    "\n",
    "    # Setup base model, freezing the base model layers and considering pretrained weights on imagenet\n",
    "    base_model = tf.keras.applications.EfficientNetV2S(include_top=False, \n",
    "                                                       weights=\"imagenet\", \n",
    "                                                       input_shape=input_shape\n",
    "                                                       )  \n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=input_shape, name=\"input_layer\")\n",
    " \n",
    "    a1 = base_model(inputs, training=False)   # training = True, only last 20 layers are trainable,  \n",
    "                                          # training = False, BatchNorms and Dropouts are freezed during training  very important\n",
    "\n",
    "    # Hybrid pooling\n",
    "    gap = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(a1)\n",
    "    gmp = tf.keras.layers.GlobalMaxPooling2D(name=\"max_pooling_layer\")(a1)\n",
    "    a2 = tf.keras.layers.Concatenate(name=\"max_avg_pooling\")([gap, gmp])\n",
    "\n",
    "    # Dropout\n",
    "    a3 = tf.keras.layers.Dropout(dropout_rate)(a2)  # add dropout layer and a bit stronger on small data\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\", name=\"output_layer\")(a3)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs), base_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c480755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, base_model = build_food101_model(\n",
    "                                            input_shape=(384, 384, 3),\n",
    "                                            num_classes=101,\n",
    "                                            dropout_rate=0.5\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3591b51e",
   "metadata": {},
   "source": [
    "### Phase 1 10% data (Feature extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b8e912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: /mnt/d/04_Food101-EfficientNetV2S-model/notebook/transfer_learning/10_percent_data_aug/20260108-134520\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 13:45:25.344710: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - ETA: 0s - loss: 6.9153 - accuracy: 0.1048\n",
      "Epoch 1: val_accuracy improved from -inf to 0.36491, saving model to checkpoints/ckpt_model_10p.ckpt\n",
      "237/237 [==============================] - 176s 633ms/step - loss: 6.9153 - accuracy: 0.1048 - val_loss: 3.0533 - val_accuracy: 0.3649\n",
      "Epoch 2/5\n",
      "237/237 [==============================] - ETA: 0s - loss: 4.7866 - accuracy: 0.2453\n",
      "Epoch 2: val_accuracy improved from 0.36491 to 0.44214, saving model to checkpoints/ckpt_model_10p.ckpt\n",
      "237/237 [==============================] - 164s 690ms/step - loss: 4.7866 - accuracy: 0.2453 - val_loss: 2.7120 - val_accuracy: 0.4421\n",
      "Epoch 3/5\n",
      "237/237 [==============================] - ETA: 0s - loss: 4.0621 - accuracy: 0.3158\n",
      "Epoch 3: val_accuracy improved from 0.44214 to 0.44657, saving model to checkpoints/ckpt_model_10p.ckpt\n",
      "237/237 [==============================] - 130s 547ms/step - loss: 4.0621 - accuracy: 0.3158 - val_loss: 2.6758 - val_accuracy: 0.4466\n",
      "Epoch 4/5\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.7503 - accuracy: 0.3567\n",
      "Epoch 4: val_accuracy improved from 0.44657 to 0.49018, saving model to checkpoints/ckpt_model_10p.ckpt\n",
      "237/237 [==============================] - 129s 544ms/step - loss: 3.7503 - accuracy: 0.3567 - val_loss: 2.4668 - val_accuracy: 0.4902\n",
      "Epoch 5/5\n",
      "237/237 [==============================] - ETA: 0s - loss: 3.5390 - accuracy: 0.3914\n",
      "Epoch 5: val_accuracy improved from 0.49018 to 0.53604, saving model to checkpoints/ckpt_model_10p.ckpt\n",
      "237/237 [==============================] - 126s 532ms/step - loss: 3.5390 - accuracy: 0.3914 - val_loss: 2.2431 - val_accuracy: 0.5360\n"
     ]
    }
   ],
   "source": [
    "# Freeze backbone (Phase 1)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# \n",
    "model_10p = model\n",
    "\n",
    "# Compile (feature extraction)    \n",
    "model_10p.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(), # add label smoothing\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  metrics=[\"accuracy\"]\n",
    "                  )\n",
    "\n",
    "# Train\n",
    "history_10p = model_10p.fit(ds_train_10,\n",
    "                          epochs=5,\n",
    "                          validation_data=ds_val,                          \n",
    "                          callbacks=[hf.create_tensorboard_callback(\"transfer_learning\", \"10_percent_data_aug\"), \n",
    "                                      ckpt_model_10p]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef29da7",
   "metadata": {},
   "source": [
    "Final validation Top-1 accuracy: 53.56%\n",
    "\n",
    "This is exactly where a frozen-backbone EfficientNetV2S should land with:\n",
    "\n",
    "            only 10% of Food101\n",
    "            strong augmentation\n",
    "            no label smoothing\n",
    "            mixed precision\n",
    "            short training (5 epochs)\n",
    "            You nailed it.\n",
    "\n",
    "ðŸ§  How to correctly interpret this (important)\n",
    "\n",
    "        1ï¸âƒ£ Val accuracy > train accuracy â†’ EXPECTED\n",
    "            This is not a bug.\n",
    "        Why:\n",
    "            Training data has augmentation + dropout\n",
    "            Validation data is clean\n",
    "            Backbone is frozen\n",
    "            Food101 training split is noisy by design\n",
    "            This is normal and healthy in Phase-1.\n",
    "\n",
    "        2ï¸âƒ£ Loss curve behavior is correct\n",
    "\n",
    "            Train loss steadily â†“ (6.86 â†’ 3.50)\n",
    "            Val loss steadily â†“ (3.10 â†’ 2.11)\n",
    "            No NaNs\n",
    "            No instability\n",
    "\n",
    "        This confirms:\n",
    "            Mixed precision is stable\n",
    "            Output dtype fix worked\n",
    "\n",
    "Learning rate is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16264e68",
   "metadata": {},
   "source": [
    "### Phase 2 - 50% data \n",
    "\n",
    "- Epochs: 5 â†’ 20\n",
    "- Trainable: unfreeze last ~20â€“30 layers only \n",
    "- LR: 3e-5 (big drop from Phase 1), AdamW weight_decay=1e-5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87c90a",
   "metadata": {},
   "source": [
    "Why freezing BatchNorm is so important (Food101 specific)\n",
    "\n",
    "EfficientNetâ€™s BatchNorm layers:\n",
    "    Were trained on ImageNet\n",
    "    Contain very strong, stable statistics\n",
    "\n",
    "    Are extremely sensitive to:\n",
    "        Small batch sizes\n",
    "        Dataset shift\n",
    "        Aggressive augmentation\n",
    "\n",
    "If you unfreeze BN layers:\n",
    "\n",
    "        Validation accuracy often drops\n",
    "        Training becomes unstable\n",
    "        Convergence slows or oscillates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c384a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Unfreeze last N layers of the backbone\n",
    "N = 30\n",
    "\n",
    "# 1) freeze everything first\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 2) unfreeze the tail, but keep BN frozen\n",
    "for layer in base_model.layers[-N:]:\n",
    "    layer.trainable = not isinstance(layer, tf.keras.layers.BatchNormalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fe7cb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: /mnt/d/04_Food101-EfficientNetV2S-model/notebook/transfer_learning/50_percent_data_aug/20260108-135726\n",
      "Epoch 6/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 1.8014 - accuracy: 0.5408\n",
      "Epoch 6: val_accuracy improved from -inf to 0.74008, saving model to checkpoints/ckpt_model_50p.ckpt\n",
      "1184/1184 [==============================] - 485s 389ms/step - loss: 1.8014 - accuracy: 0.5408 - val_loss: 0.9551 - val_accuracy: 0.7401\n",
      "Epoch 7/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 1.3068 - accuracy: 0.6530\n",
      "Epoch 7: val_accuracy improved from 0.74008 to 0.75893, saving model to checkpoints/ckpt_model_50p.ckpt\n",
      "1184/1184 [==============================] - 467s 394ms/step - loss: 1.3068 - accuracy: 0.6530 - val_loss: 0.8664 - val_accuracy: 0.7589\n",
      "Epoch 8/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 1.0938 - accuracy: 0.7037\n",
      "Epoch 8: val_accuracy improved from 0.75893 to 0.78780, saving model to checkpoints/ckpt_model_50p.ckpt\n",
      "1184/1184 [==============================] - 453s 382ms/step - loss: 1.0938 - accuracy: 0.7037 - val_loss: 0.7602 - val_accuracy: 0.7878\n",
      "Epoch 9/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.9494 - accuracy: 0.7374\n",
      "Epoch 9: val_accuracy improved from 0.78780 to 0.79925, saving model to checkpoints/ckpt_model_50p.ckpt\n",
      "1184/1184 [==============================] - 443s 374ms/step - loss: 0.9494 - accuracy: 0.7374 - val_loss: 0.7319 - val_accuracy: 0.7992\n",
      "Epoch 10/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.8377 - accuracy: 0.7660\n",
      "Epoch 10: val_accuracy did not improve from 0.79925\n",
      "1184/1184 [==============================] - 442s 373ms/step - loss: 0.8377 - accuracy: 0.7660 - val_loss: 0.7354 - val_accuracy: 0.7982\n",
      "Epoch 11/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.7400 - accuracy: 0.7883\n",
      "Epoch 11: val_accuracy improved from 0.79925 to 0.80198, saving model to checkpoints/ckpt_model_50p.ckpt\n",
      "1184/1184 [==============================] - 443s 374ms/step - loss: 0.7400 - accuracy: 0.7883 - val_loss: 0.7313 - val_accuracy: 0.8020\n",
      "Epoch 12/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.6691 - accuracy: 0.8085\n",
      "Epoch 12: val_accuracy improved from 0.80198 to 0.80630, saving model to checkpoints/ckpt_model_50p.ckpt\n",
      "1184/1184 [==============================] - 442s 373ms/step - loss: 0.6691 - accuracy: 0.8085 - val_loss: 0.7367 - val_accuracy: 0.8063\n",
      "Epoch 13/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.8225\n",
      "Epoch 13: val_accuracy improved from 0.80630 to 0.80756, saving model to checkpoints/ckpt_model_50p.ckpt\n",
      "1184/1184 [==============================] - 443s 374ms/step - loss: 0.6083 - accuracy: 0.8225 - val_loss: 0.7464 - val_accuracy: 0.8076\n",
      "Epoch 14/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.8347\n",
      "Epoch 14: val_accuracy improved from 0.80756 to 0.80768, saving model to checkpoints/ckpt_model_50p.ckpt\n",
      "1184/1184 [==============================] - 451s 380ms/step - loss: 0.5513 - accuracy: 0.8347 - val_loss: 0.7743 - val_accuracy: 0.8077\n",
      "Epoch 15/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.5004 - accuracy: 0.8509\n",
      "Epoch 15: val_accuracy did not improve from 0.80768\n",
      "1184/1184 [==============================] - 441s 373ms/step - loss: 0.5004 - accuracy: 0.8509 - val_loss: 0.8158 - val_accuracy: 0.8046\n",
      "Epoch 16/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.8586\n",
      "Epoch 16: val_accuracy did not improve from 0.80768\n",
      "1184/1184 [==============================] - 441s 372ms/step - loss: 0.4658 - accuracy: 0.8586 - val_loss: 0.8047 - val_accuracy: 0.8069\n",
      "Epoch 17/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8680\n",
      "Epoch 17: val_accuracy improved from 0.80768 to 0.80840, saving model to checkpoints/ckpt_model_50p.ckpt\n",
      "1184/1184 [==============================] - 442s 373ms/step - loss: 0.4377 - accuracy: 0.8680 - val_loss: 0.7986 - val_accuracy: 0.8084\n",
      "Epoch 18/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.4009 - accuracy: 0.8797\n",
      "Epoch 18: val_accuracy did not improve from 0.80840\n",
      "1184/1184 [==============================] - 441s 372ms/step - loss: 0.4009 - accuracy: 0.8797 - val_loss: 0.8591 - val_accuracy: 0.8049\n",
      "Epoch 19/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.8840\n",
      "Epoch 19: val_accuracy improved from 0.80840 to 0.80990, saving model to checkpoints/ckpt_model_50p.ckpt\n",
      "1184/1184 [==============================] - 443s 373ms/step - loss: 0.3782 - accuracy: 0.8840 - val_loss: 0.8553 - val_accuracy: 0.8099\n",
      "Epoch 20/20\n",
      "1184/1184 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.8897\n",
      "Epoch 20: val_accuracy did not improve from 0.80990\n",
      "1184/1184 [==============================] - 441s 372ms/step - loss: 0.3602 - accuracy: 0.8897 - val_loss: 0.8989 - val_accuracy: 0.8076\n"
     ]
    }
   ],
   "source": [
    "ckpt_model_50p = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoints/ckpt_model_50p.ckpt\",\n",
    "                                                    save_weights_only=True,\n",
    "                                                    save_best_only=True,\n",
    "                                                    monitor=\"val_accuracy\",\n",
    "                                                    save_freq=\"epoch\",\n",
    "                                                    verbose=1)\n",
    "\n",
    "model_50p = model_10p\n",
    "\n",
    "# Load best Phase-1 weights\n",
    "model_50p.load_weights(\"checkpoints/ckpt_model_10p.ckpt\")\n",
    "\n",
    "# Recompile with lower LR\n",
    "model_50p.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4, weight_decay=1e-5),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Train on 50% data\n",
    "history_50p = model_50p.fit(ds_train_50,\n",
    "                            initial_epoch=5,                          \n",
    "                            epochs=20,                          \n",
    "                            validation_data=ds_val,                          \n",
    "                             callbacks=[hf.create_tensorboard_callback(\"transfer_learning\", \"50_percent_data_aug\"), \n",
    "                                       ckpt_model_50p]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec383d1",
   "metadata": {},
   "source": [
    "### Phase 3 - 100% data \n",
    "\n",
    "- Epochs: 40 to 60\n",
    "- Trainable: unfreeze last ~20â€“30 layers only\n",
    "- learning_rate=1e-5, weight_decay=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3284324",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Unfreeze last N layers of the backbone\n",
    "N = 50\n",
    "\n",
    "# 1) freeze everything first\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 2) unfreeze the tail, but keep BN frozen\n",
    "for layer in base_model.layers[-N:]:\n",
    "    layer.trainable = not isinstance(layer, tf.keras.layers.BatchNormalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6b98005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: /mnt/d/04_Food101-EfficientNetV2S-model/notebook/transfer_learning/100_percent_data_aug/20260108-161339\n",
      "Epoch 21/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.7302 - accuracy: 0.8137\n",
      "Epoch 21: val_accuracy improved from -inf to 0.82622, saving model to checkpoints/ckpt_model_100p.ckpt\n",
      "2368/2368 [==============================] - 889s 366ms/step - loss: 0.7302 - accuracy: 0.8137 - val_loss: 0.6383 - val_accuracy: 0.8262\n",
      "Epoch 22/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.8259\n",
      "Epoch 22: val_accuracy improved from 0.82622 to 0.83145, saving model to checkpoints/ckpt_model_100p.ckpt\n",
      "2368/2368 [==============================] - 870s 367ms/step - loss: 0.6780 - accuracy: 0.8259 - val_loss: 0.6149 - val_accuracy: 0.8314\n",
      "Epoch 23/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.6492 - accuracy: 0.8320\n",
      "Epoch 23: val_accuracy improved from 0.83145 to 0.83485, saving model to checkpoints/ckpt_model_100p.ckpt\n",
      "2368/2368 [==============================] - 851s 359ms/step - loss: 0.6492 - accuracy: 0.8320 - val_loss: 0.6038 - val_accuracy: 0.8349\n",
      "Epoch 24/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.6218 - accuracy: 0.8366\n",
      "Epoch 24: val_accuracy improved from 0.83485 to 0.83695, saving model to checkpoints/ckpt_model_100p.ckpt\n",
      "2368/2368 [==============================] - 846s 357ms/step - loss: 0.6218 - accuracy: 0.8366 - val_loss: 0.5963 - val_accuracy: 0.8370\n",
      "Epoch 25/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.6026 - accuracy: 0.8425\n",
      "Epoch 25: val_accuracy improved from 0.83695 to 0.83727, saving model to checkpoints/ckpt_model_100p.ckpt\n",
      "2368/2368 [==============================] - 834s 352ms/step - loss: 0.6026 - accuracy: 0.8425 - val_loss: 0.5924 - val_accuracy: 0.8373\n",
      "Epoch 26/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.5862 - accuracy: 0.8460\n",
      "Epoch 26: val_accuracy improved from 0.83727 to 0.83964, saving model to checkpoints/ckpt_model_100p.ckpt\n",
      "2368/2368 [==============================] - 837s 353ms/step - loss: 0.5862 - accuracy: 0.8460 - val_loss: 0.5869 - val_accuracy: 0.8396\n",
      "Epoch 27/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.8491\n",
      "Epoch 27: val_accuracy improved from 0.83964 to 0.84190, saving model to checkpoints/ckpt_model_100p.ckpt\n",
      "2368/2368 [==============================] - 837s 353ms/step - loss: 0.5708 - accuracy: 0.8491 - val_loss: 0.5840 - val_accuracy: 0.8419\n",
      "Epoch 28/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.8517\n",
      "Epoch 28: val_accuracy did not improve from 0.84190\n",
      "2368/2368 [==============================] - 842s 355ms/step - loss: 0.5556 - accuracy: 0.8517 - val_loss: 0.5821 - val_accuracy: 0.8411\n",
      "Epoch 29/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.8557\n",
      "Epoch 29: val_accuracy improved from 0.84190 to 0.84206, saving model to checkpoints/ckpt_model_100p.ckpt\n",
      "2368/2368 [==============================] - 843s 356ms/step - loss: 0.5418 - accuracy: 0.8557 - val_loss: 0.5805 - val_accuracy: 0.8421\n",
      "Epoch 30/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.5212 - accuracy: 0.8602\n",
      "Epoch 30: val_accuracy did not improve from 0.84206\n",
      "2368/2368 [==============================] - 841s 355ms/step - loss: 0.5212 - accuracy: 0.8602 - val_loss: 0.5810 - val_accuracy: 0.8417\n",
      "Epoch 31/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.5113 - accuracy: 0.8625\n",
      "Epoch 31: val_accuracy did not improve from 0.84206\n",
      "2368/2368 [==============================] - 841s 355ms/step - loss: 0.5113 - accuracy: 0.8625 - val_loss: 0.5780 - val_accuracy: 0.8418\n",
      "Epoch 32/32\n",
      "2368/2368 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.8650\n",
      "Epoch 32: val_accuracy improved from 0.84206 to 0.84273, saving model to checkpoints/ckpt_model_100p.ckpt\n",
      "2368/2368 [==============================] - 841s 355ms/step - loss: 0.4988 - accuracy: 0.8650 - val_loss: 0.5797 - val_accuracy: 0.8427\n"
     ]
    }
   ],
   "source": [
    "ckpt_model_100p = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoints/ckpt_model_100p.ckpt\",\n",
    "                                                    save_weights_only=True,\n",
    "                                                    save_best_only=True,\n",
    "                                                    monitor=\"val_accuracy\",\n",
    "                                                    save_freq=\"epoch\",\n",
    "                                                    verbose=1)\n",
    "\n",
    "model_100p = model_50p\n",
    "\n",
    "# Load best Phase-2 weights\n",
    "model_100p.load_weights(\"checkpoints/ckpt_model_50p.ckpt\")\n",
    "\n",
    "# Recompile with lower LR\n",
    "model_100p.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5, weight_decay=1e-5),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Train on 100% data\n",
    "history_100p = model_100p.fit(ds_train_100,\n",
    "                              initial_epoch=20,                           \n",
    "                              epochs=32,                          \n",
    "                              validation_data=ds_val,                          \n",
    "                              callbacks=[hf.create_tensorboard_callback(\"transfer_learning\", \"100_percent_data_aug\"), \n",
    "                                         ckpt_model_100p]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e920e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m.save(\u001b[33m\"\u001b[39m\u001b[33m/mnt/d/04_Food101-EfficientNetV2S-model/models/food101_best.keras\u001b[39m\u001b[33m\"\u001b[39m, save_format=\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"/mnt/d/04_Food101-EfficientNetV2S-model/models/food101_best.keras\", save_format=\"tf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
