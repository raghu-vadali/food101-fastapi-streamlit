{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c2a104c",
   "metadata": {},
   "source": [
    "### Load --> Run --> Compute --> Cache\n",
    "\n",
    "Run inference ONCE on the evaluation dataset and compute global metrics from the exported SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8319982c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-16 14:14:11.114696: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-16 14:14:17.869795: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768569263.935005   49097 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5518 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:64:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# loading model\n",
    "from keras.layers import TFSMLayer\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "SAVED_MODEL_DIR = pathlib.Path(\n",
    "    \"/mnt/d/04_Food101-EfficientNetV2S-model/models/export/food101_savedmodel\"\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    TFSMLayer(SAVED_MODEL_DIR.as_posix(), call_endpoint=\"serving_default\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ac0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building evaluation dataset\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(ds_train, ds_val), ds_info = tfds.load(\n",
    "                                            \"food101\",\n",
    "                                            split=[\"train\", \"validation\"],\n",
    "                                            shuffle_files=False,\n",
    "                                            as_supervised=True,\n",
    "                                            with_info=True,\n",
    "                                        )\n",
    "\n",
    "IMG_SIZE = (384, 384)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def preprocess_fn(image, label):\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.keras.applications.efficientnet_v2.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "test_ds = (\n",
    "                ds_val\n",
    "                .map(preprocess_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                .batch(BATCH_SIZE)\n",
    "                .prefetch(tf.data.AUTOTUNE)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e971433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class_names = ds_info.features[\"label\"].names\n",
    "\n",
    "with open(\"class_names.json\", \"w\") as f:\n",
    "    json.dump(class_names, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12731db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/790 [00:00<?, ?it/s]2026-01-16 14:14:37.226900: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:396] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2026-01-16 14:14:39.100749: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n",
      "100%|██████████| 790/790 [03:13<00:00,  4.27it/s]2026-01-16 14:17:50.902098: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "100%|██████████| 790/790 [03:13<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25250,) (25250, 101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Running inference ONCE and cache outputs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "y_true = []\n",
    "y_probs = []\n",
    "\n",
    "\n",
    "# For each batch in the test dataset, here we send the images through the model as each batch\n",
    "# the model runs vectorized inference on the whole batch at once.\n",
    "# in this case test_ds is (num_batches, batch_size, height, width, channels)\n",
    "for images, labels in tqdm(test_ds):                                # tqdm adds a progress bar (useful for long evaluations)\n",
    "    outputs = model(images)\n",
    "    probs = outputs[\"output_layer\"]\n",
    "\n",
    "    y_true.append(labels.numpy())\n",
    "    y_probs.append(probs.numpy())\n",
    "\n",
    "y_true = np.concatenate(y_true)     # Earlier labels were stored as list of arrays(batches), now we concatenate them into a single array(each image's label)\n",
    "y_probs = np.concatenate(y_probs)\n",
    "y_pred = np.argmax(y_probs, axis=1)\n",
    "\n",
    "print(y_true.shape, y_probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456b9f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.8427\n",
      "Top-5 Accuracy: 0.9668\n"
     ]
    }
   ],
   "source": [
    "# Compute global metrics\n",
    "top1_acc = np.mean(y_pred == y_true)\n",
    "\n",
    "top5_preds = np.argsort(y_probs, axis=1)[:, -5:]  #sort indeces of probs(lowest to highest) and take last 5 (top 5)\n",
    "top5_acc = np.mean(\n",
    "    [y_true[i] in top5_preds[i] for i in range(len(y_true))]\n",
    ")\n",
    "\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.4f}\")\n",
    "print(f\"Top-5 Accuracy: {top5_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b0744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache everything (CRITICAL)\n",
    "# It simply stores your arrays to disk\n",
    "\n",
    "np.save(\"y_true.npy\", y_true)\n",
    "np.save(\"y_pred.npy\", y_pred)\n",
    "np.save(\"y_probs.npy\", y_probs)\n",
    "\n",
    "import json\n",
    "with open(\"metrics.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"top1_accuracy\": float(top1_acc),\n",
    "            \"top5_accuracy\": float(top5_acc),\n",
    "            \"num_samples\": int(len(y_true)),\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
